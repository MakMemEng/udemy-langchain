{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LSkqxoVN3J6"
      },
      "source": [
        "# Udemy講座「LangChainによる大規模言語モデル（LLM）アプリケーション開発入門」のコース前半のソースコード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVs2pKa2ODmT"
      },
      "source": [
        "## 2. GPT の API の基礎知識"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLGNNT3BOWFp"
      },
      "source": [
        "### 2.4. OpenAI の API キーを発行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import join, dirname\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(verbose=True)\n",
        "\n",
        "# dotenv_path = join(dirname(__file__), '.env')\n",
        "load_dotenv()\n",
        "# load_dotenv(dotenv_path)\n",
        "\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0cuW-PeOD_s"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYVHgMnrOez3"
      },
      "source": [
        "### 2.5. OpenAI の Completions API にふれる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2cPPmp7IOGbU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-80dhzVAY7hBIunpJbMd9bTd8FSkjJ\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1695163331,\n",
            "  \"model\": \"text-davinci-003\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n\\nHello there! How are you doing today?\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 2,\n",
            "    \"completion_tokens\": 11,\n",
            "    \"total_tokens\": 13\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://api.openai.com/v1/completions\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer \" + os.environ[\"OPENAI_API_KEY\"]\n",
        "}\n",
        "data = {\n",
        "    \"model\": \"text-davinci-003\",\n",
        "    \"prompt\": \"hello!\",\n",
        "    \"temperature\": 0,\n",
        "}\n",
        "\n",
        "response = requests.post(url=url, headers=headers, json=data)\n",
        "print(json.dumps(response.json(), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY7cd-EeOwiN"
      },
      "source": [
        "### 2.6. OpenAI の Chat API にふれる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bOzgI4KGOIcj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-80di8fpjTLa0pNiYkp03MLokMbGOL\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1695163340,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Hello! How can I assist you today?\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 9,\n",
            "    \"completion_tokens\": 9,\n",
            "    \"total_tokens\": 18\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "url = \"https://api.openai.com/v1/chat/completions\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer \" + os.environ[\"OPENAI_API_KEY\"]\n",
        "}\n",
        "data = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"hello!\"}\n",
        "    ],\n",
        "    \"temperature\": 0,\n",
        "}\n",
        "\n",
        "response = requests.post(url=url, headers=headers, json=data)\n",
        "print(json.dumps(response.json(), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlDl6XqsOzFx"
      },
      "source": [
        "## 4. LangChain 入門（前半）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVO4MzQxPJDC"
      },
      "source": [
        "### 4.3. Models（LLMs・Chat Models）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVxZFGSagE1C"
      },
      "outputs": [],
      "source": [
        "# !pip install --quiet langchain==0.0.172 openai==0.27.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gJHDUhwwgKc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "はじめまして、私は○○と申します。現在、○○大学で学んでいます。趣味は料理や旅行などです。特に料理は好きで、毎日新しいレシピを試しています。今までに海外旅行も何回かしていて、異文化に触れるのが大好きです。今後も新しいことに挑戦していきたいと思っています。よろしくお願いします。\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
        "\n",
        "result = llm.predict(\"自己紹介してください。\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OShyvz70hRD2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "こんにちは、私はAIです。私はOpenAIが開発した自然言語処理モデルです。私の目的は、ユーザーが質問や要求をすると、最善の回答や応答を提供することです。私は様々なトピックについての情報を持っており、文法やスタイルの修正も行うことができます。どのようにお手伝いできますか？\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "result = chat.predict(\"自己紹介してください。\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9XTxsN8xitv"
      },
      "source": [
        "### 4.4. Prompts（Prompt Templates）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-sZIx1e8iwJ8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "次のコマンドの概要を説明してください。\n",
            "\n",
            "コマンド: ls\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "次のコマンドの概要を説明してください。\n",
        "\n",
        "コマンド: {command}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"command\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "result = prompt.format(command=\"ls\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0eKtJGu0vX6"
      },
      "source": [
        "### 4.5. Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9QyYR_Iixyuy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "次のコマンドの概要を説明してください。\n",
            "\n",
            "コマンド: ls\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "lsコマンドは、UnixやUnix系のオペレーティングシステムで使用されるコマンドで、指定されたディレクトリ内のファイルやディレクトリの一覧を表示するために使用されます。デフォルトでは、現在のディレクトリの内容が表示されますが、オプションを使用して他のディレクトリの内容を表示することもできます。ファイルやディレクトリの名前、パーミッション、所有者、サイズなどの情報が表示されます。\n"
          ]
        }
      ],
      "source": [
        "import langchain\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "langchain.verbose = True\n",
        "\n",
        "# Model を用意\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# Prompt を用意\n",
        "template = \"\"\"\n",
        "次のコマンドの概要を説明してください。\n",
        "\n",
        "コマンド: {command}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"command\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Chain を作成\n",
        "chain = LLMChain(llm=chat, prompt=prompt)\n",
        "\n",
        "# 実行\n",
        "result = chain.run(\"ls\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BETIBsg104QZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "以下の質問に回答してください。\n",
            "\n",
            "### 質問 ###\n",
            "私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\n",
            "### 質問終了 ###\n",
            "\n",
            "ステップバイステップで考えましょう。\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m1. 最初に市場で10個のリンゴを買いました。\n",
            "2. 隣人に2つのリンゴを渡しました。残りは8個です。\n",
            "3. 修理工に2つのリンゴを渡しました。残りは6個です。\n",
            "4. さらに5つのリンゴを買いました。残りは11個です。\n",
            "5. 1つのリンゴを食べました。残りは10個です。\n",
            "\n",
            "したがって、残りのリンゴは10個です。\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "入力を結論だけ一言に要約してください。\n",
            "\n",
            "### 入力 ###\n",
            "1. 最初に市場で10個のリンゴを買いました。\n",
            "2. 隣人に2つのリンゴを渡しました。残りは8個です。\n",
            "3. 修理工に2つのリンゴを渡しました。残りは6個です。\n",
            "4. さらに5つのリンゴを買いました。残りは11個です。\n",
            "5. 1つのリンゴを食べました。残りは10個です。\n",
            "\n",
            "したがって、残りのリンゴは10個です。\n",
            "### 入力終了 ###\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m最初に10個のリンゴを買い、渡したり食べたりした後も残りは10個です。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "最初に10個のリンゴを買い、渡したり食べたりした後も残りは10個です。\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "langchain.verbose = True\n",
        "\n",
        "# Model を用意\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# 1 つ目の Prompt と Chain を用意\n",
        "cot_template = \"\"\"\n",
        "以下の質問に回答してください。\n",
        "\n",
        "### 質問 ###\n",
        "{question}\n",
        "### 質問終了 ###\n",
        "\n",
        "ステップバイステップで考えましょう。\n",
        "\"\"\"\n",
        "cot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=cot_template,\n",
        ")\n",
        "cot_chain = LLMChain(llm=chat, prompt=cot_prompt)\n",
        "\n",
        "# 2 つ目の Prompt と Chain を用意\n",
        "summarize_template = \"\"\"\n",
        "入力を結論だけ一言に要約してください。\n",
        "\n",
        "### 入力 ###\n",
        "{input}\n",
        "### 入力終了 ###\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\"],\n",
        "    template=summarize_template,\n",
        ")\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
        "\n",
        "# 2 つの Chain を直列に繋ぐ\n",
        "cot_summarize_chain = SimpleSequentialChain(\n",
        "    chains=[cot_chain, summarize_chain])\n",
        "\n",
        "# 実行\n",
        "result = cot_summarize_chain(\n",
        "    \"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\")\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1fNzjTRRl7u"
      },
      "source": [
        "### 4.7. Prompts のより高度な機能（Output Parses）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkm0Ys9k4t3h"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from typing import List\n",
        "\n",
        "langchain.verbose = True\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    ingredients: List[str] = Field(description=\"ingredients of the dish\")\n",
        "    steps: List[str] = Field(description=\"steps to make the dish\")\n",
        "\n",
        "template = \"\"\"料理のレシピを教えてください。\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "料理名: {dish}\n",
        "\"\"\"\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"dish\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=chat, prompt=prompt)\n",
        "\n",
        "output = chain.run(dish=\"カレー\")\n",
        "print(\"=== output ===\")\n",
        "print(output)\n",
        "\n",
        "recipe = parser.parse(output)\n",
        "print(\"=== recipe object ===\")\n",
        "print(recipe)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkfHWlKnSjSG"
      },
      "source": [
        "## 5. LangChain 入門（後半）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prFUg4G3QfbA"
      },
      "source": [
        "### 5.2. Indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VY_0R_VGcHv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/hwchase17/langchain.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhcQzqUqR1t3"
      },
      "outputs": [],
      "source": [
        "!cd langchain && git checkout v0.0.172"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znXiN1W1Rd8Q"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet unstructured==0.6.6 tabulate==0.9.0 pdf2image==1.16.3 pytesseract==0.3.10 chromadb==0.3.23 tiktoken==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q10Ff7vNQuV1"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "\n",
        "loader = DirectoryLoader(\"./langchain/docs/\", glob=\"**/*.md\")\n",
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJbppn-lRblc"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "result = index.query(\"LangChainの概要を1文で説明してください。\", llm=chat)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARj8Y8_RdlD6"
      },
      "source": [
        "### 5.4. Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7pxRwGnUDvn"
      },
      "outputs": [],
      "source": [
        "def post_chat_completions(content):\n",
        "  url = \"https://api.openai.com/v1/chat/completions\"\n",
        "  headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": \"Bearer \" + os.environ[\"OPENAI_API_KEY\"]\n",
        "  }\n",
        "  data = {\n",
        "      \"model\": \"gpt-3.5-turbo\",\n",
        "      \"messages\": [\n",
        "          {\"role\": \"user\", \"content\": content}\n",
        "      ],\n",
        "      \"temperature\": 0,\n",
        "  }\n",
        "\n",
        "  response = requests.post(url=url, headers=headers, json=data)\n",
        "  print(json.dumps(response.json(), indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_OBzUQGVAwa"
      },
      "outputs": [],
      "source": [
        "post_chat_completions(\"Hi! I'm Oshima!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYjoBKp8VAjZ"
      },
      "outputs": [],
      "source": [
        "post_chat_completions(\"Do you know my name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ctwcsZ-VLdD"
      },
      "outputs": [],
      "source": [
        "post_chat_completions(\"\"\"Human: Hi! I'm Oshima!\n",
        "AI: Hello Oshima! I'm an AI language model. How can I assist you today?\n",
        "Human: Do you know my name?\n",
        "AI: \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjkhKO7nVeEK"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "langchain.verbose = True\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=100)\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "    ai_message = conversation.predict(input=user_message)\n",
        "    print(f\"AI: {ai_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0xTWbzzV4_n"
      },
      "source": [
        "### 5.5. Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbSTOTuKX7kJ"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "langchain.verbose = True\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], llm=chat)\n",
        "agent_chain = initialize_agent(\n",
        "    tools, chat, agent=\"zero-shot-react-description\")\n",
        "\n",
        "result = agent_chain.run(\"What is your current directory?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqrKxwnhlstV"
      },
      "source": [
        "### 5.8. Chat API に特化した実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX1cLM9FJfbe"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import openai\n",
        "\n",
        "langchain.verbose = True\n",
        "openai.log = \"debug\"\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=100)\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "    ai_message = conversation.predict(input=user_message)\n",
        "    print(f\"AI: {ai_message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X90oA5kIPGYG"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=100)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"Hi! I'm Oshima!\")\n",
        "]\n",
        "\n",
        "result = chat(messages)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZAE9dogmna_"
      },
      "outputs": [],
      "source": [
        "langchain.verbose = True\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "    memory.chat_memory.add_user_message(user_message)\n",
        "\n",
        "    ai_message = chat(memory.chat_memory.messages)\n",
        "    memory.chat_memory.add_ai_message(ai_message.content)\n",
        "    print(f\"AI: {ai_message.content}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyhA5HVJLGI-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
